# ğŸš€ OpenAI API ì‚¬ìš© ê°€ì´ë“œ

ì´ ë¬¸ì„œëŠ” ìµœì‹  `openai` ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±, ë©€í‹°ëª¨ë‹¬(ì´ë¯¸ì§€) ë¶„ì„, ê·¸ë¦¬ê³  ëŒ€í™”í˜• ì„¸ì…˜ì„ êµ¬í˜„í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

---

## 1. í™˜ê²½ ì¤€ë¹„

### 1.1 API í‚¤ ë°œê¸‰

1. [OpenAI Platform](https://platform.openai.com/)ì—ì„œ API í‚¤ë¥¼ ë°œê¸‰ë°›ìŠµë‹ˆë‹¤.
2. í”„ë¡œì íŠ¸ ë£¨íŠ¸ í´ë”ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  í‚¤ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.
```text
OPENAI_API_KEY=your_actual_api_key_here
```



### 1.2 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install -U openai python-dotenv pillow
```

---

## 2. ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒì„± (Basic Text Generation)

ê°€ì¥ ê¸°ë³¸ì ì¸ í…ìŠ¤íŠ¸ ì§ˆë¬¸-ë‹µë³€ ì˜ˆì œì…ë‹ˆë‹¤.

```python
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def generate_text():
    response = client.responses.create(
        model="gpt-4.1-mini",
        input="ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ì— ëŒ€í•´ ì§§ê²Œ ì„¤ëª…í•´ì¤˜."
    )
    print("--- í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼ ---")
    print(response.output_text)

if __name__ == "__main__":
    generate_text()
```

---

## 3. ë©€í‹°ëª¨ë‹¬ ì…ë ¥ (Multimodal: Text & Image)

í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ë¥¼ ë™ì‹œì— ì…ë ¥í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì˜ˆì œì…ë‹ˆë‹¤.

```python
import base64
import os
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def encode_image_to_data_url(image_path):
    with open(image_path, "rb") as image_file:
        encoded = base64.b64encode(image_file.read()).decode("utf-8")
    return f"data:image/jpeg;base64,{encoded}"

def analyze_image():
    image_path = Path(__file__).resolve().parent / "sample_image.jpg"
    image_url = encode_image_to_data_url(str(image_path))

    response = client.responses.create(
        model="gpt-4.1-mini",
        input=[
            {
                "role": "user",
                "content": [
                    {"type": "input_text", "text": "ì´ ì‚¬ì§„ì˜ ë¶„ìœ„ê¸°ì™€ ì£¼ìš” ì‚¬ë¬¼ì„ ì„¤ëª…í•´ì¤˜."},
                    {"type": "input_image", "image_url": image_url},
                ],
            }
        ],
    )

    print("--- ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ---")
    print(response.output_text)

analyze_image()
```

---

## 4. ëŒ€í™”í˜• ì„¸ì…˜ (Chat Session)

ì´ì „ ëŒ€í™” ë§¥ë½ì„ ìœ ì§€í•˜ë©´ì„œ ìƒí˜¸ì‘ìš©í•˜ëŠ” ì±„íŒ… ì˜ˆì œì…ë‹ˆë‹¤.

```python
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def start_chat():
    messages = [{"role": "user", "content": "ì•ˆë…•! ë‚˜ëŠ” íŒŒì´ì¬ ê°œë°œìì•¼."}]

    response1 = client.responses.create(
        model="gpt-4.1-mini",
        input=messages,
    )
    print(f"AI: {response1.output_text}")

    messages.append({"role": "assistant", "content": response1.output_text})
    messages.append({"role": "user", "content": "ë‚´ê°€ ë°©ê¸ˆ ë‚˜ë¥¼ ëˆ„êµ¬ë¼ê³  ì†Œê°œí–ˆì—ˆì§€?"})

    response2 = client.responses.create(
        model="gpt-4.1-mini",
        input=messages,
    )
    print(f"AI: {response2.output_text}")

start_chat()
```

---

## 5. í•µì‹¬ ê¸°ëŠ¥ ìš”ì•½

| ê¸°ëŠ¥ | ì‚¬ìš© ë©”ì„œë“œ | íŠ¹ì§• |
| --- | --- | --- |
| **í…ìŠ¤íŠ¸ ìƒì„±** | `client.responses.create()` | ë‹¨ë°œì„± ì§ˆë¬¸ ë° ìš”ì²­ ì²˜ë¦¬ |
| **ë©€í‹°ëª¨ë‹¬** | `input=[text, image]` | ì´ë¯¸ì§€, ë¬¸ì„œ ë“± ë³µí•© ë°ì´í„° ë¶„ì„ |
| **ì±„íŒ… ì„¸ì…˜** | `input=messages` | ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì§ì ‘ ê´€ë¦¬ |
